{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install textract\n",
    "!pip install transformers\n",
    "!pip install peft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'textract'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/akeem/Nextcloud/git_courses/template/Demo_Custom_Chat/chat_2.ipynb Cell 1\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/akeem/Nextcloud/git_courses/template/Demo_Custom_Chat/chat_2.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/akeem/Nextcloud/git_courses/template/Demo_Custom_Chat/chat_2.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/akeem/Nextcloud/git_courses/template/Demo_Custom_Chat/chat_2.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtextract\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/akeem/Nextcloud/git_courses/template/Demo_Custom_Chat/chat_2.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m Dataset\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/akeem/Nextcloud/git_courses/template/Demo_Custom_Chat/chat_2.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoModelForSeq2SeqLM\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'textract'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import os\n",
    "import pandas as pd\n",
    "import textract\n",
    "from datasets import Dataset\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from peft import PeftModel, PeftConfig\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "peft_model_id = \"smangrul/twitter_complaints_bigscience_T0_3B_LORA_SEQ_2_SEQ_LM\"\n",
    "config = PeftConfig.from_pretrained(peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_unzip(url, folder_name):\n",
    "    # Create the folder if it doesn't exist\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    # Download the file\n",
    "    response = requests.get(url)\n",
    "    zip_path = os.path.join(folder_name, 'temp.zip')\n",
    "    with open(zip_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "    # Unzip the file\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(folder_name)\n",
    "\n",
    "    # Remove the zip file\n",
    "    os.remove(zip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_path = \"https://jrssbcrsefilesnait.blob.core.windows.net/3950data1/Archive.zip\"\n",
    "unzip_folder = \"train_data\"\n",
    "\n",
    "download_and_unzip(zip_path, unzip_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_path):\n",
    "    _, ext = os.path.splitext(file_path)\n",
    "    if ext in ['.txt', '.csv']:\n",
    "        with open(file_path, 'r') as file:\n",
    "            return file.read()\n",
    "    elif ext in ['.docx', '.pdf']:\n",
    "        return textract.process(file_path).decode()\n",
    "\n",
    "def create_dataset(folder_path, tokenizer_name):\n",
    "    texts = []\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            text = read_file(file_path)\n",
    "            if text:\n",
    "                texts.append(text)\n",
    "    dataset = Dataset.from_pandas(pd.DataFrame(texts, columns=['text']))\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    tokenized_dataset = dataset.map(lambda x: tokenizer(x['text']), batched=True)\n",
    "    return tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_dataset(unzip_folder, config.base_model_name_or_path)\n",
    "for i, item in enumerate(dataset):\n",
    "    if i == 0:\n",
    "        print(item)\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
